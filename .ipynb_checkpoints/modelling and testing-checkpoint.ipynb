{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Testing-to-see-how-well-metadata-alone-predicts-toxicity\" data-toc-modified-id=\"Testing-to-see-how-well-metadata-alone-predicts-toxicity-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Testing to see how well metadata alone predicts toxicity</a></span><ul class=\"toc-item\"><li><span><a href=\"#Testing-the-performance-of-XGBoost\" data-toc-modified-id=\"Testing-the-performance-of-XGBoost-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Testing the performance of XGBoost</a></span></li><li><span><a href=\"#testing-using-tfidf-vectorizer\" data-toc-modified-id=\"testing-using-tfidf-vectorizer-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>testing using tfidf vectorizer</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-06T06:48:38.338691Z",
     "start_time": "2018-08-06T06:48:38.317704Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy as sp\n",
    "import re\n",
    "import xgboost as xgb\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer, HashingVectorizer, TfidfTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression, LinearRegression, Lasso, Ridge, ElasticNet, RidgeCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-06T05:54:35.342960Z",
     "start_time": "2018-08-06T05:54:29.155420Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-06T05:54:35.365950Z",
     "start_time": "2018-08-06T05:54:35.345956Z"
    }
   },
   "outputs": [],
   "source": [
    "def downsample(df):\n",
    "    return df.drop(df[df.is_toxic == 0].sample(len(df[df.is_toxic == 0]) - df.is_toxic.sum()).index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-06T05:54:37.069256Z",
     "start_time": "2018-08-06T05:54:35.368944Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['comment_text_char_space', 'question', 'exclamation', 'words',\n",
       "       'avg_word_len', 'caps_percentage'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing to see how well metadata alone predicts toxicity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-08T02:25:17.786558Z",
     "start_time": "2018-08-08T02:25:12.665700Z"
    }
   },
   "outputs": [],
   "source": [
    "# building a function to peform train test split and simple regression on different target variables\n",
    "def tester(x_values, y_value):\n",
    "    \n",
    "    df = pd.read_csv('cleaned.csv')\n",
    "    \n",
    "    print('Predictors: {}'.format(x_values))\n",
    "    print(\"Target: '{}'\\n\".format(y_value))\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(df[x_values], df[y_value])\n",
    "    df = pd.concat([X_train, y_train], axis=1)    \n",
    "    downsampled = df.drop(df[df[y_value] == 0].sample(len(df[df[y_value] == 0]) - df[y_value].sum()).index)\n",
    "    X_train = downsampled.drop(y_train.name, axis=1)\n",
    "    y_train = downsampled[y_train.name]\n",
    "    \n",
    "    ss = StandardScaler()\n",
    "    X_train = ss.fit_transform(X_train)\n",
    "    X_test = ss.transform(X_test)\n",
    "    \n",
    "#     slr = LinearRegression()\n",
    "#     slr.fit(X_train, y_train)\n",
    "#     print('Linear Regression score is {}'.format(slr.score(X_test, y_test)))\n",
    " \n",
    "#     ridge = Ridge()\n",
    "#     ridge.fit(X_train, y_train)\n",
    "#     print('Ridge Regression score is {}'.format(ridge.score(X_test, y_test)))\n",
    "    \n",
    "    logit = LogisticRegression()\n",
    "    logit.fit(X_train, y_train)\n",
    "    print('Logistic Regression score is {}'.format(logit.score(X_test, y_test)))\n",
    "    \n",
    "    rfc = RandomForestClassifier()\n",
    "    rfc.fit(X_train, y_train)\n",
    "    print('Random Forest Classifier score is {}'.format(rfc.score(X_test, y_test)))\n",
    "    \n",
    "    xgboost = xgb.XGBClassifier(max_depth=5, silent=False)\n",
    "    xgboost.fit(X_train, y_train)\n",
    "    print('XGBoost score is {}'.format(xgboost.score(X_test, y_test)))\n",
    "\n",
    "    print('Majority class proportion is {}\\n'.format(pd.DataFrame(y_test.values)[0].value_counts()[0] / len(y_test)))\n",
    "    \n",
    "    # takes the higher scoring model and prints the confusion matrix using it as a predictor\n",
    "    print(confusion_matrix(y_test, sorted(zip([logit.score(X_test, y_test), rfc.score(X_test, y_test)], [logit, rfc]), reverse=True)[0][1].predict(X_test)), '\\n')\n",
    "    \n",
    "    print(classification_report(y_test, sorted(zip([logit.score(X_test, y_test), rfc.score(X_test, y_test)], [logit, rfc]), reverse=True)[0][1].predict(X_test)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-08T02:32:25.177385Z",
     "start_time": "2018-08-08T02:26:41.647058Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictors: ['question', 'exclamation', 'words', 'avg_word_len', 'caps_percentage']\n",
      "Target: 'toxic'\n",
      "\n",
      "Logistic Regression score is 0.769624188332038\n",
      "Random Forest Classifier score is 0.6795447138165317\n",
      "XGBoost score is 0.7121869280718028\n",
      "Majority class proportion is 0.9043548023165442\n",
      "\n",
      "[[29242  6830]\n",
      " [ 2359  1456]] \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.93      0.81      0.86     36072\n",
      "          1       0.18      0.38      0.24      3815\n",
      "\n",
      "avg / total       0.85      0.77      0.80     39887\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "Predictors: ['question', 'exclamation', 'words', 'avg_word_len', 'caps_percentage']\n",
      "Target: 'severe_toxic'\n",
      "\n",
      "Logistic Regression score is 0.8535111690525735\n",
      "Random Forest Classifier score is 0.762955348860531\n",
      "XGBoost score is 0.7821846716975456\n",
      "Majority class proportion is 0.9902725198686289\n",
      "\n",
      "[[33871  5628]\n",
      " [  215   173]] \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.86      0.92     39499\n",
      "          1       0.03      0.45      0.06       388\n",
      "\n",
      "avg / total       0.98      0.85      0.91     39887\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "Predictors: ['question', 'exclamation', 'words', 'avg_word_len', 'caps_percentage']\n",
      "Target: 'obscene'\n",
      "\n",
      "Logistic Regression score is 0.7894050693208313\n",
      "Random Forest Classifier score is 0.691628851505503\n",
      "XGBoost score is 0.7018326773134104\n",
      "Majority class proportion is 0.9468749216536716\n",
      "\n",
      "[[30702  7066]\n",
      " [ 1334   785]] \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      0.81      0.88     37768\n",
      "          1       0.10      0.37      0.16      2119\n",
      "\n",
      "avg / total       0.91      0.79      0.84     39887\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "Predictors: ['question', 'exclamation', 'words', 'avg_word_len', 'caps_percentage']\n",
      "Target: 'threat'\n",
      "\n",
      "Logistic Regression score is 0.750971494471883\n",
      "Random Forest Classifier score is 0.7376839571790308\n",
      "XGBoost score is 0.7188808383683907\n",
      "Majority class proportion is 0.9970416426404592\n",
      "\n",
      "[[29879  9890]\n",
      " [   43    75]] \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       1.00      0.75      0.86     39769\n",
      "          1       0.01      0.64      0.01       118\n",
      "\n",
      "avg / total       1.00      0.75      0.85     39887\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "Predictors: ['question', 'exclamation', 'words', 'avg_word_len', 'caps_percentage']\n",
      "Target: 'insult'\n",
      "\n",
      "Logistic Regression score is 0.7870484117632311\n",
      "Random Forest Classifier score is 0.6913781432546945\n",
      "XGBoost score is 0.7033369268182615\n",
      "Majority class proportion is 0.9518389450196806\n",
      "\n",
      "[[30653  7313]\n",
      " [ 1181   740]] \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.96      0.81      0.88     37966\n",
      "          1       0.09      0.39      0.15      1921\n",
      "\n",
      "avg / total       0.92      0.79      0.84     39887\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "Predictors: ['question', 'exclamation', 'words', 'avg_word_len', 'caps_percentage']\n",
      "Target: 'identity_hate'\n",
      "\n",
      "Logistic Regression score is 0.8117933161180334\n",
      "Random Forest Classifier score is 0.6937348008122948\n",
      "XGBoost score is 0.7112091658936496\n",
      "Majority class proportion is 0.9915260611226715\n",
      "\n",
      "[[32237  7312]\n",
      " [  195   143]] \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.99      0.82      0.90     39549\n",
      "          1       0.02      0.42      0.04       338\n",
      "\n",
      "avg / total       0.99      0.81      0.89     39887\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "Predictors: ['question', 'exclamation', 'words', 'avg_word_len', 'caps_percentage']\n",
      "Target: 'total_toxic'\n",
      "\n",
      "Logistic Regression score is 0.8982876626469777\n",
      "Random Forest Classifier score is 0.8101386416626971\n",
      "XGBoost score is 0.894476897234688\n",
      "Majority class proportion is 0.9004186827788503\n",
      "\n",
      "[[35731    46     0   138     0     0     0]\n",
      " [ 1490    33     0    64     1     0     0]\n",
      " [  759    15     0    31     1     0     0]\n",
      " [  924    26     0    65     0     0     0]\n",
      " [  393    20     0    46     1     0     0]\n",
      " [   74     9     0    15     0     0     0]\n",
      " [    3     1     0     1     0     0     0]] \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.91      0.99      0.95     35915\n",
      "          1       0.22      0.02      0.04      1588\n",
      "          2       0.00      0.00      0.00       806\n",
      "          3       0.18      0.06      0.09      1015\n",
      "          4       0.33      0.00      0.00       460\n",
      "          5       0.00      0.00      0.00        98\n",
      "          6       0.00      0.00      0.00         5\n",
      "\n",
      "avg / total       0.83      0.90      0.86     39887\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "Predictors: ['question', 'exclamation', 'words', 'avg_word_len', 'caps_percentage']\n",
      "Target: 'is_toxic'\n",
      "\n",
      "Logistic Regression score is 0.7678190889262165\n",
      "Random Forest Classifier score is 0.6739539198235014\n",
      "XGBoost score is 0.7040389099205255\n",
      "Majority class proportion is 0.89806202522125\n",
      "\n",
      "[[29075  6746]\n",
      " [ 2515  1551]] \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      0.81      0.86     35821\n",
      "          1       0.19      0.38      0.25      4066\n",
      "\n",
      "avg / total       0.85      0.77      0.80     39887\n",
      "\n",
      "---------------------------------------------------------------------------\n",
      "Predictors: ['question', 'exclamation', 'words', 'avg_word_len', 'caps_percentage']\n",
      "Target: 'is_toxic_no_profanity'\n",
      "\n",
      "Logistic Regression score is 0.7652618647679695\n",
      "Random Forest Classifier score is 0.6787424474139444\n",
      "XGBoost score is 0.708727154210645\n",
      "Majority class proportion is 0.8997668413267481\n",
      "\n",
      "[[29074  6815]\n",
      " [ 2548  1450]] \n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.92      0.81      0.86     35889\n",
      "          1       0.18      0.36      0.24      3998\n",
      "\n",
      "avg / total       0.84      0.77      0.80     39887\n",
      "\n",
      "---------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for toxicity in ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate', 'total_toxic', 'is_toxic', 'is_toxic_no_profanity']:\n",
    "    tester(['question', 'exclamation', 'words', 'avg_word_len', 'caps_percentage'], toxicity)\n",
    "    print('-'*75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## testing using tfidf vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-06T06:26:38.572177Z",
     "start_time": "2018-08-06T06:26:38.465238Z"
    }
   },
   "outputs": [],
   "source": [
    "def nlpscorer(nlp):\n",
    "    \n",
    "    df = pd.read_csv('cleaned.csv')\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df[['comment_text_char_space', 'question', 'exclamation', 'words',\n",
    "                                                            'avg_word_len', 'caps_percentage']], df['is_toxic_no_profanity'])\n",
    "    \n",
    "    df = pd.concat([X_train, y_train], axis=1)    \n",
    "    downsampled = df.drop(df[df['is_toxic_no_profanity'] == 0].sample(len(df[df['is_toxic_no_profanity'] == 0]) - df['is_toxic_no_profanity'].sum()).index)\n",
    "    X_train = downsampled.drop(y_train.name, axis=1)\n",
    "    y_train = downsampled[y_train.name]\n",
    "    \n",
    "    nlp.fit(X_train.comment_text_char_space)\n",
    "    transformed = nlp.transform(X_train.comment_text_char_space)\n",
    "    X_train.drop('comment_text_char_space', axis=1).shape\n",
    "    xgboost.fit(transformed, y_train)\n",
    "    \n",
    "    print('NLP ONLY')\n",
    "    print(classification_report(y_test, xgboost.predict(nlp.transform(X_test.comment_text_char_space))))\n",
    "    print(pd.DataFrame(confusion_matrix(y_test, xgboost.predict(nlp.transform(X_test.comment_text_char_space))), index=['true_0', 'true_1'], columns=['predicted_0', 'predicted_1']), '\\n')\n",
    "    print('NLP only score: ', xgboost.score(nlp.transform(X_test.comment_text_char_space), y_test), '\\n')\n",
    "    \n",
    "    X_train_combined = sp.sparse.hstack([transformed, sp.sparse.csr_matrix(X_train.drop('comment_text_char_space', axis=1))])\n",
    "    X_test_combined = sp.sparse.hstack([nlp.transform(X_test.comment_text_char_space), sp.sparse.csr_matrix(X_test.drop('comment_text_char_space', axis=1))])\n",
    "    xgboost.fit(X_train_combined, y_train)\n",
    "    \n",
    "    print('COMBINED')\n",
    "    print(classification_report(y_test, xgboost.predict(X_test_combined)))\n",
    "    print(pd.DataFrame(confusion_matrix(y_test, xgboost.predict(X_test_combined)), index=['true_0', 'true_1'], columns=['predicted_0', 'predicted_1']), '\\n')\n",
    "    print('Combined score: ', xgboost.score(X_test_combined, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-06T06:35:54.840216Z",
     "start_time": "2018-08-06T06:35:54.835219Z"
    }
   },
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(stop_words='english', ngram_range=(1,3), max_df=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-06T06:41:44.009344Z",
     "start_time": "2018-08-06T06:36:05.772102Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NLP ONLY\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      0.95      0.96     35876\n",
      "          1       0.60      0.70      0.64      4011\n",
      "\n",
      "avg / total       0.93      0.92      0.92     39887\n",
      "\n",
      "        predicted_0  predicted_1\n",
      "true_0        33987         1889\n",
      "true_1         1214         2797 \n",
      "\n",
      "NLP only score:  0.9222052297741119 \n",
      "\n",
      "COMBINED\n",
      "\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.97      0.91      0.94     35876\n",
      "          1       0.50      0.76      0.60      4011\n",
      "\n",
      "avg / total       0.92      0.90      0.91     39887\n",
      "\n",
      "        predicted_0  predicted_1\n",
      "true_0        32778         3098\n",
      "true_1          951         3060 \n",
      "\n",
      "Combined score:  0.8984882292476245\n"
     ]
    }
   ],
   "source": [
    "nlpscorer(tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
